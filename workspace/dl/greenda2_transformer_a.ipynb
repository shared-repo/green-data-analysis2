{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer, TfIdfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Korpora\n",
    "# !pip install tokenizers\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Korpora import Korpora\n",
    "\n",
    "from tokenizers import ByteLevelBPETokenizer, BertWordPieceTokenizer\n",
    "from transformers import BertTokenizer, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmc = Korpora.load('nsmc', force_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('아 더빙.. 진짜 짜증나네요 목소리',\n",
       "  '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나',\n",
       "  '너무재밓었다그래서보는것을추천한다',\n",
       "  '교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정',\n",
       "  '사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다'),\n",
       " ('굳 ㅋ',\n",
       "  'GDNTOPCLASSINTHECLUB',\n",
       "  '뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아',\n",
       "  '지루하지는 않은데 완전 막장임... 돈주고 보기에는....',\n",
       "  '3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc.train.texts[:5], nsmc.test.texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "if os.path.exists('data-files/nsmc'):\n",
    "    shutil.rmtree('data-files/nsmc')\n",
    "\n",
    "os.mkdir('data-files/nsmc')\n",
    "\n",
    "with open('data-files/nsmc/train.txt', 'w', encoding='utf-8') as f:\n",
    "    for line in nsmc.train.get_all_texts():\n",
    "        f.write(f\"{line}\\n\")\n",
    "with open('data-files/nsmc/test.txt', 'w', encoding='utf-8') as f:\n",
    "    for line in nsmc.test.get_all_texts():\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data-files/nsmc/wordpiece\\\\vocab.txt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists('data-files/nsmc/wordpiece'):\n",
    "    shutil.rmtree('data-files/nsmc/wordpiece')\n",
    "os.mkdir('data-files/nsmc/wordpiece')\n",
    "\n",
    "wordpiece_tokenizer = BertWordPieceTokenizer(lowercase=False)\n",
    "wordpiece_tokenizer.train(\n",
    "    ['data-files/nsmc/train.txt', 'data-files/nsmc/test.txt'],\n",
    "    vocab_size=10000\n",
    ") # 단어사전 학습\n",
    "\n",
    "wordpiece_tokenizer.save_model('data-files/nsmc/wordpiece')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(\"data-files/nsmc/wordpiece\", do_lower_case=False)\n",
    "\n",
    "print(nsmc.train.texts[:5])\n",
    "[bert_tokenizer.tokenize(sentence) for sentence in nsmc.train.texts[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bert_tokenizer(\n",
    "    nsmc.train.texts[:5],\n",
    "    padding='max_length',\n",
    "    max_length=12,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( result.keys() )\n",
    "result['input_ids'] # 단어 식별 번호로 구성된 문장 목록\n",
    "result['token_type_ids'] # 단어가 포함된 문서의 순서 번호\n",
    "result['attention_mask'] # 단어가 포함된 문서의 순서 번호"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
