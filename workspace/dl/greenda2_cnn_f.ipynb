{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P4QWNlE53jaU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as tf_keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "cp drive/MyDrive/Colab\\ Notebooks/data-files/dogs-vs-cats.zip sample_data/\n",
        "unzip sample_data/dogs-vs-cats.zip -d sample_data\n",
        "unzip sample_data/dogs-vs-cats/train.zip -d sample_data/dogs-vs-cats\n",
        "unzip sample_data/dogs-vs-cats/test1.zip -d sample_data/dogs-vs-cats\n",
        "mv sample_data/dogs-vs-cats/test1 sample_data/dogs-vs-cats/test\n",
        "rm -rf sample_data/__MACOSX"
      ],
      "metadata": {
        "id": "JtljH31CAcD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "src_base = 'sample_data/dogs-vs-cats'\n",
        "dest_base = 'sample_data/dogs-vs-cats2'\n",
        "\n",
        "if os.path.exists(dest_base): # 경로 존재여부 확인\n",
        "  shutil.rmtree(dest_base) # train 경로 및 하위 경로 삭제\n",
        "os.mkdir(dest_base) # 디렉터리 만들기\n",
        "\n",
        "# train 폴더의 0 ~ 1000 : train, 1000 ~ 1500 : validation, 1500 ~ 2000 : test 세트로 구성\n",
        "for start, stop, path in zip([0, 1000, 1500], [1000, 1500, 2000], ['train', 'validation', 'test']):\n",
        "  os.mkdir(os.path.join(dest_base, path))\n",
        "  for sub_path in ['cat', 'dog']:\n",
        "    os.mkdir(os.path.join(dest_base, path, sub_path))\n",
        "    for idx in np.arange(start, stop):\n",
        "      fname = f'{sub_path}.{idx}.jpg'\n",
        "      shutil.copy(os.path.join(src_base, 'train', fname), os.path.join(dest_base, path, sub_path, fname)) # 파일 복사"
      ],
      "metadata": {
        "id": "ZX8kSSc0NT0Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 자동화 도구 만들기 : 파일을 읽어서 모델에 입력 가능한 형식으로 변환하는 도구\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_generator = ImageDataGenerator(rescale=1/255) # 특정 디렉터리의 파일을 읽어서 모델의 입력데이터로 변환하는 도구\n",
        "validation_data_generator = ImageDataGenerator(rescale=1/255)\n",
        "test_data_generator = ImageDataGenerator(rescale=1/255)"
      ],
      "metadata": {
        "id": "ig1ds40CiKtW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generator를 사용해서 파일 데이터 읽기\n",
        "datasets = []\n",
        "for path, generator in zip(['train', 'validation', 'test'],\n",
        "                           [train_data_generator, validation_data_generator, test_data_generator]):\n",
        "  dataset = generator.flow_from_directory(directory=f\"sample_data/dogs-vs-cats2/{path}\",\n",
        "                                          target_size=(256, 256),\n",
        "                                          batch_size=32,\n",
        "                                          class_mode=\"binary\")\n",
        "  datasets.append(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsEuBNIIjwQS",
        "outputId": "054d266b-cd28-4207-a64c-d92b388f7e51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미 학습 완료된 비슷한 모델 활용 ( 전이학습 )\n",
        "\n",
        "# 1. 다른 모델의 합성곱 층이 출력한 데이터를 현재 모델의 입력으로 사용\n",
        "# 2. 다른 모델과 현재 모델 결합 1 (다른 모델의 합성곱 층에 층을 추가해서 새 모델 구성 - 다른 모델의 합성곱 층은 학습하지 않음 )\n",
        "# 3. 다른 모델과 현재 모델 결합 2 (다른 모델의 합성곱 층에 층을 추가해서 새 모델 구성 - 다른 모델의 합성곱 층의 일부는 학습 )"
      ],
      "metadata": {
        "id": "ZeVdCMjfNORe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사전 학습 모델 준비\n",
        "\n",
        "base_model = tf_keras.applications.vgg16.VGG16(include_top=False,\n",
        "                                               weights='imagenet',\n",
        "                                               input_shape=(256, 256, 3))\n",
        "\n",
        "base_model.trainable = False # 모델 학습 X -> 가중치 업데이트 X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0dh5iEWPiL3",
        "outputId": "ffd9491f-f100-4a1c-ee0b-7c431f7fabe5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS3XcREqRfzI",
        "outputId": "dc9e6e77-0d62-4043-8adf-da5069415cb0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-g4LqgdF1bU",
        "outputId": "002f8c24-0554-4ac3-ca10-b9eb8cf726fc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.src.engine.functional.Functional"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = tf_keras.layers.Input(shape=(256, 256, 3))\n",
        "# input = tf_keras.applications.vgg16.preprocess_input(input)\n",
        "x = base_model(input)\n",
        "x = tf_keras.layers.Flatten()(x)\n",
        "x = tf_keras.layers.Dense(units=512, activation=\"relu\")(x)\n",
        "output = tf_keras.layers.Dense(units=1, activation='sigmoid')(x)\n",
        "model = tf_keras.models.Model(input, output)"
      ],
      "metadata": {
        "id": "qfSghLwb_luC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Xb5IigK2Bmth"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(datasets[0], epochs=10, validation_data=datasets[1])"
      ],
      "metadata": {
        "id": "2MTU6pRQBxmi"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}