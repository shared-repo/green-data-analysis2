{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YhVGMzSvokGf"
      },
      "outputs": [],
      "source": [
        "# !pip install nltk\n",
        "# !pip install accelerate\n",
        "# !pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T7GIu7_wokGg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from datasets import load_metric\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSnhSF23okGg",
        "outputId": "1437bfb5-3e4d-439f-b33f-cac71112d5b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download(\"movie_reviews\")\n",
        "fieldids = movie_reviews.fileids()\n",
        "reviews = [ movie_reviews.raw(fieldid) for fieldid in fieldids ]\n",
        "categories = [ movie_reviews.categories(fieldid) for fieldid in fieldids ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPJ555w8okGg",
        "outputId": "6c864ea0-bc5a-4bd0-8132-a99256f00f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# labeled_categories = LabelEncoder().fit_transform(categories)\n",
        "labeled_categories = LabelEncoder().fit_transform(categories).tolist()\n",
        "labeled_categories[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LmcSKYVGokGh"
      },
      "outputs": [],
      "source": [
        "X_train, X_test ,y_train, y_test = \\\n",
        "    train_test_split(reviews, labeled_categories, stratify=labeled_categories, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT4-LS4yokGh",
        "outputId": "9c2cfc70-4be1-4adf-cb81-a0547655b4f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "train_inputs = tokenizer(X_train, truncation=True, padding=True, return_tensors='pt')\n",
        "test_inputs = tokenizer(X_test, truncation=True, padding=True, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFElO7JfokGh",
        "outputId": "4d80d432-9c61-452c-eefb-4992a203e3d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1500, 512]) torch.Size([500, 512])\n",
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "print( train_inputs['input_ids'].shape, test_inputs['input_ids'].shape )\n",
        "\n",
        "for item in train_inputs.items():\n",
        "    print(item[1][2].shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MUY3ZQmmokGh"
      },
      "outputs": [],
      "source": [
        "class ReviewDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, inputs, labels):\n",
        "        self.inputs = inputs\n",
        "        self.labels = labels\n",
        "        pass\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input = { k: torch.tensor(v[idx]) for k, v in self.inputs.items() }\n",
        "        input['label'] = torch.tensor(self.labels[idx])\n",
        "        return input\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = ReviewDataset(train_inputs, y_train)\n",
        "test_dataset = ReviewDataset(test_inputs, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOqusbbvokGi",
        "outputId": "1bb31a8f-3a7f-4190-a6f0-34a8c471e00d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'label'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-4faa0d83da1d>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input = { k: torch.tensor(v[idx]) for k, v in self.inputs.items() }\n"
          ]
        }
      ],
      "source": [
        "for data in train_dataset:\n",
        "    print(data.keys())\n",
        "    # print(data)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiUZwDIEokGi",
        "outputId": "6bdba77d-ce71-4713-ae6b-1fb7d05ede95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "device_name = \"cuda:0\" if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device(device_name)\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "P8wnX6ZKokGi",
        "outputId": "5979dddd-70f5-476e-b6d3-6575c5520bab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-11-1e32037e6839>:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric('accuracy')\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:753: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.1/metrics/accuracy/accuracy.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "<ipython-input-8-4faa0d83da1d>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input = { k: torch.tensor(v[idx]) for k, v in self.inputs.items() }\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [940/940 13:22, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.369000</td>\n",
              "      <td>0.686723</td>\n",
              "      <td>0.844000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-4faa0d83da1d>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input = { k: torch.tensor(v[idx]) for k, v in self.inputs.items() }\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=940, training_loss=0.21839773502755672, metrics={'train_runtime': 803.9834, 'train_samples_per_second': 9.329, 'train_steps_per_second': 1.169, 'total_flos': 1973332915200000.0, 'train_loss': 0.21839773502755672, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "metric = load_metric('accuracy')\n",
        "def compute_metrics(evaluation_dataset):\n",
        "    logits, labels = evaluation_dataset\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "train_args = TrainingArguments(\n",
        "    output_dir=\"checkpoints\",\n",
        "    num_train_epochs=5,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    args=train_args\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "iUr8RYd7PFZQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "batch_size = 1\n",
        "all_prediction_labels = []\n",
        "for idx in range(len(y_test)//batch_size):\n",
        "    # input_texts = X_train[idx*batch_size:(idx+1)*batch_size]\n",
        "    input_texts = X_test[idx*batch_size:(idx+1)*batch_size]\n",
        "    inputs = tokenizer(input_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    inputs = inputs.to(device)\n",
        "    result = model(**inputs) # ì˜ˆì¸¡\n",
        "    predictions = torch.softmax(result.logits, dim=1)\n",
        "    prediction_labels = predictions.cpu().detach().numpy().argmax(axis=1)\n",
        "    all_prediction_labels.extend(prediction_labels.tolist())\n",
        "\n",
        "accuracy = (np.array(all_prediction_labels) == np.array(y_test)).sum() / len(y_test)\n",
        "print(f\"train accuracy : {accuracy}\")"
      ],
      "metadata": {
        "id": "cJz-GMf32oGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "p3UtrpExVF2P",
        "outputId": "526118fc-4cb8-48f9-c20a-0267a205ab1b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-4faa0d83da1d>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input = { k: torch.tensor(v[idx]) for k, v in self.inputs.items() }\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:17]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.7529026865959167,\n",
              " 'eval_accuracy': 0.882,\n",
              " 'eval_runtime': 17.4033,\n",
              " 'eval_samples_per_second': 28.73,\n",
              " 'eval_steps_per_second': 3.62,\n",
              " 'epoch': 5.0}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}