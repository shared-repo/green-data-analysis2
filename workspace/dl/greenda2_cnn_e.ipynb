{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P4QWNlE53jaU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as tf_keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "cp drive/MyDrive/Colab\\ Notebooks/data-files/dogs-vs-cats.zip sample_data/\n",
        "unzip sample_data/dogs-vs-cats.zip -d sample_data\n",
        "unzip sample_data/dogs-vs-cats/train.zip -d sample_data/dogs-vs-cats\n",
        "unzip sample_data/dogs-vs-cats/test1.zip -d sample_data/dogs-vs-cats\n",
        "mv sample_data/dogs-vs-cats/test1 sample_data/dogs-vs-cats/test\n",
        "rm -rf sample_data/__MACOSX"
      ],
      "metadata": {
        "id": "JtljH31CAcD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "src_base = 'sample_data/dogs-vs-cats'\n",
        "dest_base = 'sample_data/dogs-vs-cats2'\n",
        "\n",
        "if os.path.exists(dest_base): # 경로 존재여부 확인\n",
        "  shutil.rmtree(dest_base) # train 경로 및 하위 경로 삭제\n",
        "os.mkdir(dest_base) # 디렉터리 만들기\n",
        "\n",
        "# train 폴더의 0 ~ 1000 : train, 1000 ~ 1500 : validation, 1500 ~ 2000 : test 세트로 구성\n",
        "for start, stop, path in zip([0, 1000, 1500], [1000, 1500, 2000], ['train', 'validation', 'test']):\n",
        "  os.mkdir(os.path.join(dest_base, path))\n",
        "  for sub_path in ['cat', 'dog']:\n",
        "    os.mkdir(os.path.join(dest_base, path, sub_path))\n",
        "    for idx in np.arange(start, stop):\n",
        "      fname = f'{sub_path}.{idx}.jpg'\n",
        "      shutil.copy(os.path.join(src_base, 'train', fname), os.path.join(dest_base, path, sub_path, fname)) # 파일 복사"
      ],
      "metadata": {
        "id": "ZX8kSSc0NT0Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 자동화 도구 만들기 : 파일을 읽어서 모델에 입력 가능한 형식으로 변환하는 도구\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_generator = ImageDataGenerator(rescale=1/255) # 특정 디렉터리의 파일을 읽어서 모델의 입력데이터로 변환하는 도구\n",
        "validation_data_generator = ImageDataGenerator(rescale=1/255)\n",
        "test_data_generator = ImageDataGenerator(rescale=1/255)"
      ],
      "metadata": {
        "id": "ig1ds40CiKtW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generator를 사용해서 파일 데이터 읽기\n",
        "datasets = []\n",
        "for path, generator in zip(['train', 'validation', 'test'],\n",
        "                           [train_data_generator, validation_data_generator, test_data_generator]):\n",
        "  dataset = generator.flow_from_directory(directory=f\"sample_data/dogs-vs-cats2/{path}\",\n",
        "                                          target_size=(256, 256),\n",
        "                                          batch_size=32,\n",
        "                                          class_mode=\"binary\")\n",
        "  datasets.append(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsEuBNIIjwQS",
        "outputId": "1e471056-a353-4138-c68f-baf62d55398c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미 학습 완료된 비슷한 모델 활용 ( 전이학습 )\n",
        "\n",
        "# 1. 다른 모델의 합성곱 층이 출력한 데이터를 현재 모델의 입력으로 사용\n",
        "# 2. 다른 모델과 현재 모델 결합 1 (다른 모델의 합성곱 층에 층을 추가해서 새 모델 구성 - 다른 모델의 합성곱 층은 학습하지 않음 )\n",
        "# 3. 다른 모델과 현재 모델 결합 2 (다른 모델의 합성곱 층에 층을 추가해서 새 모델 구성 - 다른 모델의 합성곱 층의 일부는 학습 )"
      ],
      "metadata": {
        "id": "ZeVdCMjfNORe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사전 학습 모델 준비\n",
        "\n",
        "base_model = tf_keras.applications.vgg16.VGG16(include_top=False,\n",
        "                                               weights='imagenet',\n",
        "                                               input_shape=(256, 256, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0dh5iEWPiL3",
        "outputId": "dfee5994-f976-4c89-b897-77a9e37deec7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS3XcREqRfzI",
        "outputId": "f886fc08-1eeb-447b-99cd-a9b7a8c2fe1c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 14714688 (56.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P_M9ZhkSSLog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 훈련\n",
        "\n",
        "model = tf_keras.Sequential([\n",
        "    tf_keras.layers.Input(shape=(256, 256, 3)),\n",
        "    # 합성곱 층 ( 이미지의 특성 읽는 층 )\n",
        "    tf_keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    tf_keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    tf_keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    tf_keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    tf_keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    tf_keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "\n",
        "    # 완전 연결 층 ( 이미지를 판별하는 층 )\n",
        "    tf_keras.layers.Flatten(),\n",
        "    tf_keras.layers.Dense(units=512, activation='relu'),\n",
        "    tf_keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "vWDxeEFZrw7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "# tf_keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "FWm6hCdXtePW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BLJTlsNbt5-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(datasets[0],\n",
        "                    steps_per_epoch=60, epochs=20,\n",
        "                    validation_data=datasets[1], validation_steps=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukBAbkWYwEQa",
        "outputId": "0262361c-8206-418d-a9dc-02bc00e0bf0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "60/60 [==============================] - 10s 164ms/step - loss: 0.6071 - accuracy: 0.6859 - val_loss: 0.6350 - val_accuracy: 0.6438\n",
            "Epoch 2/20\n",
            "60/60 [==============================] - 8s 129ms/step - loss: 0.5176 - accuracy: 0.7516 - val_loss: 0.6225 - val_accuracy: 0.6906\n",
            "Epoch 3/20\n",
            "60/60 [==============================] - 9s 155ms/step - loss: 0.4104 - accuracy: 0.8167 - val_loss: 0.6097 - val_accuracy: 0.6812\n",
            "Epoch 4/20\n",
            "60/60 [==============================] - 10s 174ms/step - loss: 0.2740 - accuracy: 0.8845 - val_loss: 0.7138 - val_accuracy: 0.7188\n",
            "Epoch 5/20\n",
            "60/60 [==============================] - 8s 135ms/step - loss: 0.1510 - accuracy: 0.9433 - val_loss: 0.8842 - val_accuracy: 0.7094\n",
            "Epoch 6/20\n",
            "60/60 [==============================] - 9s 153ms/step - loss: 0.0935 - accuracy: 0.9674 - val_loss: 1.1393 - val_accuracy: 0.6854\n",
            "Epoch 7/20\n",
            "60/60 [==============================] - 10s 158ms/step - loss: 0.0433 - accuracy: 0.9884 - val_loss: 1.4016 - val_accuracy: 0.6948\n",
            "Epoch 8/20\n",
            "60/60 [==============================] - 8s 129ms/step - loss: 0.0524 - accuracy: 0.9839 - val_loss: 1.5507 - val_accuracy: 0.6854\n",
            "Epoch 9/20\n",
            "60/60 [==============================] - 11s 179ms/step - loss: 0.0722 - accuracy: 0.9800 - val_loss: 1.5361 - val_accuracy: 0.6594\n",
            "Epoch 10/20\n",
            "60/60 [==============================] - 12s 197ms/step - loss: 0.0450 - accuracy: 0.9844 - val_loss: 1.5691 - val_accuracy: 0.6583\n",
            "Epoch 11/20\n",
            "60/60 [==============================] - 9s 156ms/step - loss: 0.0393 - accuracy: 0.9884 - val_loss: 1.8380 - val_accuracy: 0.6687\n",
            "Epoch 12/20\n",
            "60/60 [==============================] - 8s 130ms/step - loss: 0.0265 - accuracy: 0.9932 - val_loss: 1.6504 - val_accuracy: 0.6719\n",
            "Epoch 13/20\n",
            "60/60 [==============================] - 12s 193ms/step - loss: 0.0184 - accuracy: 0.9932 - val_loss: 1.8578 - val_accuracy: 0.6802\n",
            "Epoch 14/20\n",
            "60/60 [==============================] - 12s 192ms/step - loss: 0.0067 - accuracy: 0.9995 - val_loss: 2.0506 - val_accuracy: 0.6917\n",
            "Epoch 15/20\n",
            "60/60 [==============================] - 12s 199ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 2.2396 - val_accuracy: 0.6875\n",
            "Epoch 16/20\n",
            "60/60 [==============================] - 9s 142ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.3114 - val_accuracy: 0.6760\n",
            "Epoch 17/20\n",
            "60/60 [==============================] - 9s 142ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 2.5863 - val_accuracy: 0.6750\n",
            "Epoch 18/20\n",
            "60/60 [==============================] - 8s 139ms/step - loss: 0.0401 - accuracy: 0.9890 - val_loss: 2.0945 - val_accuracy: 0.6792\n",
            "Epoch 19/20\n",
            "60/60 [==============================] - 9s 155ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 2.3357 - val_accuracy: 0.6885\n",
            "Epoch 20/20\n",
            "60/60 [==============================] - 11s 178ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.4743 - val_accuracy: 0.6844\n"
          ]
        }
      ]
    }
  ]
}